{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will be trying the transformer architecture\n",
    "This choice is motivated by the fact that the transformer excels at seqtoseq, and is able to capture dependencies spatially and temporally. I hypothesize that this is a good fit for the task since ECOG data is very complex and has dependencies in both time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper hyper parameters\n",
    "# run optuna?\n",
    "train = False\n",
    "run_optuna = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vectors(coords, resolution):\n",
    "    \"\"\"\n",
    "    Calculate the average vectors of x and y magnitudes given a resolution.\n",
    "\n",
    "    Parameters:\n",
    "    coords (list of tuples): An array of (x, y) coordinates.\n",
    "    resolution (int): The resolution number.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: An array of vectors of x and y magnitudes.\n",
    "    \"\"\"\n",
    "    if resolution <= 0:\n",
    "        raise ValueError(\"Resolution must be a positive integer.\")\n",
    "    \n",
    "    n = len(coords)\n",
    "    if resolution > n:\n",
    "        raise ValueError(\"Resolution cannot be greater than the length of the coordinates array.\")\n",
    "    \n",
    "    # Calculate the segment length\n",
    "    segment_length = n // resolution\n",
    "    \n",
    "    vectors = []\n",
    "    \n",
    "    for i in range(0, n, segment_length):\n",
    "        segment = coords[i:i + segment_length]\n",
    "        if len(segment) < segment_length:\n",
    "            break\n",
    "        \n",
    "        # Calculate the average change in x and y\n",
    "        delta_x = np.mean([segment[j+1][0] - segment[j][0] for j in range(len(segment) - 1)])\n",
    "        delta_y = np.mean([segment[j+1][1] - segment[j][1] for j in range(len(segment) - 1)])\n",
    "        \n",
    "        vectors.append((delta_x, delta_y))\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_joystick_readings(x, y, resolution):\n",
    "     return calculate_vectors(list(zip(x, y)), resolution)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica(X, n_components):\n",
    "    ica = FastICA(n_components=n_components)\n",
    "    S_ = ica.fit_transform(X)  # Reconstruct signals\n",
    "    A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "    return S_, A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(d1):\n",
    "    scaler = MinMaxScaler()\n",
    "    d1 = scaler.fit_transform(d1)\n",
    "    return d1\n",
    "\n",
    "def standardize_data(d1):\n",
    "    scaler = StandardScaler()\n",
    "    d1 = scaler.fit_transform(d1)\n",
    "    return d1\n",
    "\n",
    "def train_test_split(X, y, train_size):\n",
    "    train_size = int(train_size * len(X))\n",
    "    return X[:train_size], X[train_size:], y[:train_size], y[train_size:]\n",
    "\n",
    "def chunk_data(data, length):\n",
    "    chunk_size = length\n",
    "    return [data[i:i+chunk_size] for i in range(0, len(data), len(data)//chunk_size) if i+chunk_size <= len(data)]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_joystick_data(patient_idx):\n",
    "    # Load data from file\n",
    "    fname = './data/joystick_track.npz'\n",
    "    alldat = np.load(fname, allow_pickle=True)['dat']\n",
    "    dat = alldat[0]\n",
    "    d = dat[patient_idx]\n",
    "    scale_up = 10\n",
    "    # Extract ECoG data and joystick vectors\n",
    "    ecog_data = d['V']\n",
    "    targetX = d['targetX']\n",
    "    targetY = d['targetY']\n",
    "    \n",
    "    print(ecog_data.shape, targetX.shape, targetY.shape )\n",
    "    # Normalize and PCA\n",
    "    ecog_data = PCA(n_components=0.95).fit_transform(ecog_data)\n",
    "    print(ecog_data.shape, targetX.shape, targetY.shape )\n",
    "    # Set resolution and vectorize joystick readings\n",
    "    resolution = 800\n",
    "    vectors = np.array(vectorize_joystick_readings(targetX, targetY, resolution))\n",
    "    vectors = standardize_data(vectors)\n",
    "    print(ecog_data.shape, vectors.shape)\n",
    "    # Chunk ECoG data based on resolution\n",
    "    chunked_ecog_data = chunk_data(ecog_data, len(vectors))\n",
    "    # Remove data points with zero vectors\n",
    "    ecog_data, vectors = zip(*[(x, y) for x, y in zip(ecog_data, vectors) if not np.array_equal(y, [0, 0])])\n",
    "    print(len(ecog_data), len(ecog_data[0]), len(vectors))\n",
    "    print(len(chunked_ecog_data), len(chunked_ecog_data[0]), len(chunked_ecog_data[0][0]))\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(chunked_ecog_data, vectors, train_size=0.85)\n",
    "    \n",
    "    # Convert data back to numpy arrays\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248640, 64) (248640, 1) (248640, 1)\n",
      "(248640, 28) (248640, 1) (248640, 1)\n",
      "(248640, 28) (802, 2)\n",
      "802 28 802\n",
      "800 802 28\n",
      "(680, 802, 28) (680, 2)\n"
     ]
    }
   ],
   "source": [
    "patient_idx = 1\n",
    "X_train, X_test, y_train, y_test = load_process_joystick_data(patient_idx)\n",
    "min_len = min(len(X_test), len(y_test))\n",
    "X_test = X_test[:min_len]\n",
    "y_test = y_test[:min_len]\n",
    "# reshape input to be [time steps, batch size, features]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfromers: robots in disguise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swin Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.set_default_device('cuda') if torch.cuda.is_available() else torch.set_default_device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, requires_grad=True)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([680, 802, 28]) torch.Size([120, 802, 28]) torch.Size([680, 2]) torch.Size([120, 2])\n",
      "tensor([[[-3.5636e+00, -2.2142e-01,  3.5455e-01,  ..., -4.0250e-01,\n",
      "           3.7540e-01, -4.1878e-01],\n",
      "         [-4.2145e+00, -2.3734e-01,  3.7031e-01,  ..., -2.9681e-01,\n",
      "           3.7048e-01, -3.8401e-01],\n",
      "         [-4.5517e+00, -2.5918e-01,  3.8189e-01,  ..., -1.7190e-01,\n",
      "           3.6903e-01, -3.3763e-01],\n",
      "         ...,\n",
      "         [-9.1077e+00, -8.2472e-01,  1.9255e+00,  ...,  9.3772e-01,\n",
      "           1.5713e-01,  3.5137e-01],\n",
      "         [-8.6032e+00, -8.0648e-01,  1.9614e+00,  ...,  8.9451e-01,\n",
      "           1.6331e-01,  4.0367e-01],\n",
      "         [-8.7740e+00, -8.1533e-01,  2.0066e+00,  ...,  8.2623e-01,\n",
      "           1.5693e-01,  4.4119e-01]],\n",
      "\n",
      "        [[-2.8339e+00, -1.3258e+00,  1.9912e+00,  ..., -4.5152e-02,\n",
      "           1.5375e-01,  1.1417e-01],\n",
      "         [-2.8560e+00, -1.3433e+00,  1.9242e+00,  ..., -1.1944e-02,\n",
      "           1.3430e-01,  1.1008e-01],\n",
      "         [-3.0293e+00, -1.3709e+00,  1.8581e+00,  ..., -1.5693e-03,\n",
      "           1.0675e-01,  9.6199e-02],\n",
      "         ...,\n",
      "         [-4.1033e+00,  8.3983e-01, -2.2516e+00,  ..., -3.7474e-01,\n",
      "           6.9477e-02, -2.4021e-01],\n",
      "         [-3.4421e+00,  8.4270e-01, -2.1368e+00,  ..., -4.0251e-01,\n",
      "           6.6613e-02, -1.9736e-01],\n",
      "         [-3.1826e+00,  8.2384e-01, -2.0213e+00,  ..., -4.2423e-01,\n",
      "           6.5832e-02, -1.5614e-01]],\n",
      "\n",
      "        [[ 6.3126e+00, -2.0787e-01,  1.5636e+00,  ...,  2.8184e-01,\n",
      "          -1.9840e-01, -2.1055e-01],\n",
      "         [ 6.3289e+00, -2.4362e-01,  1.5872e+00,  ...,  3.2370e-01,\n",
      "          -1.8938e-01, -2.1917e-01],\n",
      "         [ 5.8911e+00, -2.6436e-01,  1.6022e+00,  ...,  3.6030e-01,\n",
      "          -1.8688e-01, -2.3538e-01],\n",
      "         ...,\n",
      "         [-2.5273e-01,  2.7942e+00,  1.2533e+00,  ...,  2.8511e-01,\n",
      "           1.0275e+00, -1.1153e-03],\n",
      "         [-2.8062e-01,  2.7251e+00,  1.1019e+00,  ...,  2.3638e-01,\n",
      "           9.7383e-01, -3.2718e-02],\n",
      "         [-9.3610e-01,  2.6187e+00,  9.2692e-01,  ...,  1.9570e-01,\n",
      "           9.1938e-01, -6.8030e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9037e+00,  1.5358e+00,  4.8683e-01,  ...,  6.2297e-01,\n",
      "          -1.9111e-01,  7.1698e-01],\n",
      "         [-3.5008e+00,  1.6553e+00,  3.9368e-01,  ...,  6.4789e-01,\n",
      "          -2.1870e-01,  7.1560e-01],\n",
      "         [-3.5184e+00,  1.6088e+00,  3.0918e-01,  ...,  6.5448e-01,\n",
      "          -2.2542e-01,  6.7793e-01],\n",
      "         ...,\n",
      "         [ 3.6225e+00, -2.7115e+00, -1.9159e+00,  ..., -7.9248e-01,\n",
      "           5.5726e-01,  2.8893e-01],\n",
      "         [ 3.2006e+00, -2.7331e+00, -1.9305e+00,  ..., -7.6533e-01,\n",
      "           5.4444e-01,  3.1514e-01],\n",
      "         [ 3.3761e+00, -2.7010e+00, -1.9585e+00,  ..., -7.4295e-01,\n",
      "           5.2517e-01,  3.3797e-01]],\n",
      "\n",
      "        [[ 9.9518e+00, -7.0566e-01,  5.1146e-01,  ..., -1.9542e-01,\n",
      "           4.7874e-01,  2.2082e-01],\n",
      "         [ 9.9497e+00, -7.4154e-01,  5.6736e-01,  ..., -2.1339e-01,\n",
      "           4.5374e-01,  2.3291e-01],\n",
      "         [ 9.5317e+00, -9.1626e-01,  6.5791e-01,  ..., -2.5714e-01,\n",
      "           4.3932e-01,  2.0353e-01],\n",
      "         ...,\n",
      "         [ 6.4710e+00,  4.0849e-01, -7.3986e-01,  ..., -2.8467e-01,\n",
      "          -2.4300e-01, -1.1317e-01],\n",
      "         [ 6.7656e+00,  4.5493e-01, -7.7431e-01,  ..., -2.4360e-01,\n",
      "          -2.5992e-01, -1.1271e-01],\n",
      "         [ 7.3586e+00,  5.3230e-01, -8.2980e-01,  ..., -2.0540e-01,\n",
      "          -2.7438e-01, -1.0860e-01]],\n",
      "\n",
      "        [[-1.5926e+01,  2.6805e+00, -2.2159e+00,  ..., -3.2383e-01,\n",
      "           1.7425e-01, -4.3499e-01],\n",
      "         [-1.5750e+01,  2.7647e+00, -2.2131e+00,  ..., -2.6026e-01,\n",
      "           1.8246e-01, -3.8816e-01],\n",
      "         [-1.5853e+01,  2.6933e+00, -2.2047e+00,  ..., -2.3318e-01,\n",
      "           2.1245e-01, -3.6993e-01],\n",
      "         ...,\n",
      "         [-1.6070e+00, -3.5752e-01,  2.2166e+00,  ...,  7.0253e-02,\n",
      "           4.5437e-01,  3.5262e-01],\n",
      "         [-2.2749e+00, -3.1669e-01,  2.2527e+00,  ...,  1.1048e-01,\n",
      "           4.9160e-01,  3.9604e-01],\n",
      "         [-2.4183e+00, -2.5891e-01,  2.2797e+00,  ...,  1.3850e-01,\n",
      "           5.0733e-01,  4.3012e-01]]], device='cuda:0', requires_grad=True) tensor([[-0.7791, -0.7308],\n",
      "        [-1.0562, -1.0090],\n",
      "        [-1.0562, -1.0090],\n",
      "        ...,\n",
      "        [ 1.1489,  1.2016],\n",
      "        [ 1.1541,  1.1987],\n",
      "        [ 0.3285,  0.9217]], device='cuda:0')\n",
      "tensor([[[-3.5636e+00, -2.2142e-01,  3.5455e-01,  ..., -4.0250e-01,\n",
      "           3.7540e-01, -4.1878e-01],\n",
      "         [-4.2145e+00, -2.3734e-01,  3.7031e-01,  ..., -2.9681e-01,\n",
      "           3.7048e-01, -3.8401e-01],\n",
      "         [-4.5517e+00, -2.5918e-01,  3.8189e-01,  ..., -1.7190e-01,\n",
      "           3.6903e-01, -3.3763e-01],\n",
      "         ...,\n",
      "         [-9.1077e+00, -8.2472e-01,  1.9255e+00,  ...,  9.3772e-01,\n",
      "           1.5713e-01,  3.5137e-01],\n",
      "         [-8.6032e+00, -8.0648e-01,  1.9614e+00,  ...,  8.9451e-01,\n",
      "           1.6331e-01,  4.0367e-01],\n",
      "         [-8.7740e+00, -8.1533e-01,  2.0066e+00,  ...,  8.2623e-01,\n",
      "           1.5693e-01,  4.4119e-01]],\n",
      "\n",
      "        [[-2.8339e+00, -1.3258e+00,  1.9912e+00,  ..., -4.5152e-02,\n",
      "           1.5375e-01,  1.1417e-01],\n",
      "         [-2.8560e+00, -1.3433e+00,  1.9242e+00,  ..., -1.1944e-02,\n",
      "           1.3430e-01,  1.1008e-01],\n",
      "         [-3.0293e+00, -1.3709e+00,  1.8581e+00,  ..., -1.5693e-03,\n",
      "           1.0675e-01,  9.6199e-02],\n",
      "         ...,\n",
      "         [-4.1033e+00,  8.3983e-01, -2.2516e+00,  ..., -3.7474e-01,\n",
      "           6.9477e-02, -2.4021e-01],\n",
      "         [-3.4421e+00,  8.4270e-01, -2.1368e+00,  ..., -4.0251e-01,\n",
      "           6.6613e-02, -1.9736e-01],\n",
      "         [-3.1826e+00,  8.2384e-01, -2.0213e+00,  ..., -4.2423e-01,\n",
      "           6.5832e-02, -1.5614e-01]],\n",
      "\n",
      "        [[ 6.3126e+00, -2.0787e-01,  1.5636e+00,  ...,  2.8184e-01,\n",
      "          -1.9840e-01, -2.1055e-01],\n",
      "         [ 6.3289e+00, -2.4362e-01,  1.5872e+00,  ...,  3.2370e-01,\n",
      "          -1.8938e-01, -2.1917e-01],\n",
      "         [ 5.8911e+00, -2.6436e-01,  1.6022e+00,  ...,  3.6030e-01,\n",
      "          -1.8688e-01, -2.3538e-01],\n",
      "         ...,\n",
      "         [-2.5273e-01,  2.7942e+00,  1.2533e+00,  ...,  2.8511e-01,\n",
      "           1.0275e+00, -1.1153e-03],\n",
      "         [-2.8062e-01,  2.7251e+00,  1.1019e+00,  ...,  2.3638e-01,\n",
      "           9.7383e-01, -3.2718e-02],\n",
      "         [-9.3610e-01,  2.6187e+00,  9.2692e-01,  ...,  1.9570e-01,\n",
      "           9.1938e-01, -6.8030e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9037e+00,  1.5358e+00,  4.8683e-01,  ...,  6.2297e-01,\n",
      "          -1.9111e-01,  7.1698e-01],\n",
      "         [-3.5008e+00,  1.6553e+00,  3.9368e-01,  ...,  6.4789e-01,\n",
      "          -2.1870e-01,  7.1560e-01],\n",
      "         [-3.5184e+00,  1.6088e+00,  3.0918e-01,  ...,  6.5448e-01,\n",
      "          -2.2542e-01,  6.7793e-01],\n",
      "         ...,\n",
      "         [ 3.6225e+00, -2.7115e+00, -1.9159e+00,  ..., -7.9248e-01,\n",
      "           5.5726e-01,  2.8893e-01],\n",
      "         [ 3.2006e+00, -2.7331e+00, -1.9305e+00,  ..., -7.6533e-01,\n",
      "           5.4444e-01,  3.1514e-01],\n",
      "         [ 3.3761e+00, -2.7010e+00, -1.9585e+00,  ..., -7.4295e-01,\n",
      "           5.2517e-01,  3.3797e-01]],\n",
      "\n",
      "        [[ 9.9518e+00, -7.0566e-01,  5.1146e-01,  ..., -1.9542e-01,\n",
      "           4.7874e-01,  2.2082e-01],\n",
      "         [ 9.9497e+00, -7.4154e-01,  5.6736e-01,  ..., -2.1339e-01,\n",
      "           4.5374e-01,  2.3291e-01],\n",
      "         [ 9.5317e+00, -9.1626e-01,  6.5791e-01,  ..., -2.5714e-01,\n",
      "           4.3932e-01,  2.0353e-01],\n",
      "         ...,\n",
      "         [ 6.4710e+00,  4.0849e-01, -7.3986e-01,  ..., -2.8467e-01,\n",
      "          -2.4300e-01, -1.1317e-01],\n",
      "         [ 6.7656e+00,  4.5493e-01, -7.7431e-01,  ..., -2.4360e-01,\n",
      "          -2.5992e-01, -1.1271e-01],\n",
      "         [ 7.3586e+00,  5.3230e-01, -8.2980e-01,  ..., -2.0540e-01,\n",
      "          -2.7438e-01, -1.0860e-01]],\n",
      "\n",
      "        [[-1.5926e+01,  2.6805e+00, -2.2159e+00,  ..., -3.2383e-01,\n",
      "           1.7425e-01, -4.3499e-01],\n",
      "         [-1.5750e+01,  2.7647e+00, -2.2131e+00,  ..., -2.6026e-01,\n",
      "           1.8246e-01, -3.8816e-01],\n",
      "         [-1.5853e+01,  2.6933e+00, -2.2047e+00,  ..., -2.3318e-01,\n",
      "           2.1245e-01, -3.6993e-01],\n",
      "         ...,\n",
      "         [-1.6070e+00, -3.5752e-01,  2.2166e+00,  ...,  7.0253e-02,\n",
      "           4.5437e-01,  3.5262e-01],\n",
      "         [-2.2749e+00, -3.1669e-01,  2.2527e+00,  ...,  1.1048e-01,\n",
      "           4.9160e-01,  3.9604e-01],\n",
      "         [-2.4183e+00, -2.5891e-01,  2.2797e+00,  ...,  1.3850e-01,\n",
      "           5.0733e-01,  4.3012e-01]]], device='cuda:0', requires_grad=True) tensor([[-0.7791, -0.7308],\n",
      "        [-1.0562, -1.0090],\n",
      "        [-1.0562, -1.0090],\n",
      "        ...,\n",
      "        [ 1.1489,  1.2016],\n",
      "        [ 1.1541,  1.1987],\n",
      "        [ 0.3285,  0.9217]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#print all shapes\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=6000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :]\n",
    "    \n",
    "class LearnedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=6000):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()[:2]\n",
    "        positions = torch.arange(seq_len).unsqueeze(0).expand(batch_size, -1)\n",
    "        return x + self.pos_embedding(positions)\n",
    "\n",
    "\n",
    "class ECoGTransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, resolution, model_dim, num_heads, num_layers, output_dim, dropout_rate=0.1):\n",
    "        super(ECoGTransformerEncoder, self).__init__()\n",
    "        # self.swin_transformer = swin_transformer_v2_t(\n",
    "        #     in_channels=input_dim,\n",
    "        #     window_size=8,\n",
    "        #     input_resolution=(resolution[0], resolution[1]),  # Adjust the input resolution based on your data\n",
    "        #     sequential_self_attention=True,\n",
    "        #     use_checkpoint=True\n",
    "        # )\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = LearnedPositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #x = self.swin_transformer(x)\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = checkpoint(self.transformer_encoder, x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new loss\n",
    "class ScaledMSELoss(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(ScaledMSELoss, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.mse_loss(input, target) * self.scale_factor\n",
    "\n",
    "# Example usage\n",
    "scale_factor = 1000  # Adjust the scale factor as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[680, 802]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "input_dim = X_train.shape[-1]\n",
    "resolution = [X_train.shape[0], X_train.shape[1]]\n",
    "model_dim = 512\n",
    "num_heads = 16\n",
    "num_layers = 13\n",
    "output_dim = 2 \n",
    "dropout_rate = 0.4444444444444444\n",
    "learning_rate = 6.794956452988361e-04\n",
    "weight_decay = 1.495499482203299e-05\n",
    "num_epochs = 3000\n",
    "print(resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'model_dim': 512, 'num_heads': 16, 'num_layers': 13, 'dropout_rate': 0.2337656400329068, 'learning_rate': 6.794956452988361e-05, 'weight_decay': 1.495499482203299e-06}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_32612\\3551750079.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = ECoGTransformerEncoder(input_dim, resolution, model_dim, num_heads, num_layers, output_dim, dropout_rate)\n",
    "\n",
    "# Ensure model parameters require gradients\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# Apply weight initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Training loop with mixed precision and gradient checkpointing\n",
    "scaler = GradScaler()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=num_epochs//7, gamma=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "\n",
    "input_tensor = X_train\n",
    "target_tensor = y_train\n",
    "dataset = TensorDataset(input_tensor, target_tensor)\n",
    "generator = torch.Generator(device='cuda')\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([802, 28]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "item = dataset[0]\n",
    "print(item[0].shape, item[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input mean: -0.0001802996703190729, Input std: 1.416823387145996\n",
      "Target mean: -0.00010602614929666743, Target std: 1.000376582145691\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input mean: {input_tensor.mean()}, Input std: {input_tensor.std()}\")\n",
    "print(f\"Target mean: {target_tensor.mean()}, Target std: {target_tensor.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([680, 802, 28]) torch.Size([680, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_32612\\1957943495.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.3668\n",
      "Epoch [1/3000], Loss: 2.1918\n",
      "Loss direction: improving\n",
      "Validation loss: 1.0465\n",
      "Epoch [2/3000], Loss: 1.3203\n",
      "Validation loss: 1.0743\n",
      "Epoch [3/3000], Loss: 1.0826\n",
      "Validation loss: 1.1201\n",
      "Epoch [4/3000], Loss: 1.0622\n",
      "Validation loss: 1.0802\n",
      "Epoch [5/3000], Loss: 1.0543\n",
      "Validation loss: 1.0230\n",
      "Epoch [6/3000], Loss: 1.0597\n",
      "Validation loss: 1.0228\n",
      "Epoch [7/3000], Loss: 1.0265\n",
      "Validation loss: 1.0160\n",
      "Epoch [8/3000], Loss: 1.0627\n",
      "Validation loss: 1.0154\n",
      "Epoch [9/3000], Loss: 1.0134\n",
      "Validation loss: 1.0038\n",
      "Epoch [10/3000], Loss: 1.0292\n",
      "Validation loss: 1.0300\n",
      "Epoch [11/3000], Loss: 1.0214\n",
      "Loss direction: improving\n",
      "Validation loss: 1.0349\n",
      "Epoch [12/3000], Loss: 1.0147\n",
      "Validation loss: 1.0266\n",
      "Epoch [13/3000], Loss: 1.0168\n",
      "Validation loss: 1.0145\n",
      "Epoch [14/3000], Loss: 1.0236\n",
      "Validation loss: 1.0177\n",
      "Epoch [15/3000], Loss: 1.0180\n",
      "Validation loss: 1.0394\n",
      "Epoch [16/3000], Loss: 1.0298\n",
      "Validation loss: 1.0552\n",
      "Epoch [17/3000], Loss: 1.0292\n",
      "Validation loss: 1.0032\n",
      "Epoch [18/3000], Loss: 1.0254\n",
      "Validation loss: 1.0020\n",
      "Epoch [19/3000], Loss: 1.0123\n",
      "Validation loss: 1.0242\n",
      "Epoch [20/3000], Loss: 1.0145\n",
      "Validation loss: 1.0231\n",
      "Epoch [21/3000], Loss: 1.0159\n",
      "Loss direction: improving\n",
      "Validation loss: 1.0052\n",
      "Epoch [22/3000], Loss: 1.0182\n",
      "Validation loss: 1.0082\n",
      "Epoch [23/3000], Loss: 1.0090\n",
      "Validation loss: 1.0049\n",
      "Epoch [24/3000], Loss: 1.0092\n",
      "Validation loss: 1.0109\n",
      "Epoch [25/3000], Loss: 1.0190\n",
      "Validation loss: 1.0020\n",
      "Epoch [26/3000], Loss: 1.0140\n",
      "Validation loss: 1.0062\n",
      "Epoch [27/3000], Loss: 1.0053\n",
      "Validation loss: 1.0051\n",
      "Epoch [28/3000], Loss: 1.0179\n",
      "Validation loss: 1.0132\n",
      "Epoch [29/3000], Loss: 1.0136\n",
      "Validation loss: 1.0052\n",
      "Epoch [30/3000], Loss: 1.0117\n",
      "Validation loss: 1.0074\n",
      "Epoch [31/3000], Loss: 1.0078\n",
      "Loss direction: improving\n",
      "Validation loss: 1.0018\n",
      "Epoch [32/3000], Loss: 1.0029\n",
      "Validation loss: 1.0047\n",
      "Epoch [33/3000], Loss: 1.0100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m     29\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[0;32m     32\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:512\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m        used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    523\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\overrides.py:1630\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[1;32m-> 1630\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "losses = []\n",
    "# Early stopping parameters\n",
    "patience = 20\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "val_loss = 0.\n",
    "def early_stop(val_loss, best_loss, patience):\n",
    "    global epochs_no_improve\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "if train:\n",
    "    model.train()\n",
    "    prev_val_loss = float('inf')  # Initialize prev_val_loss to a large value\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Step the scheduler once per epoch\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation loss\n",
    "        if bool(1):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = criterion(model(X_test), y_test).item()\n",
    "            model.train()\n",
    "            print(f'Validation loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stop(val_loss, best_loss, patience):\n",
    "            break\n",
    "        \n",
    "        # Log the average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            # Determine loss direction\n",
    "            if val_loss < prev_val_loss:\n",
    "                loss_direction = \"improving\"\n",
    "            else:\n",
    "                loss_direction = \"straying\"\n",
    "            print(f'Loss direction: {loss_direction}')\n",
    "            prev_val_loss = val_loss  # Update prev_val_loss for the next comparison\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(), f'transformer_model_p{patient_idx}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def plot_loss(losses):\n",
    "    plt.plot(losses[100:])\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "plot_loss(losses)\n",
    "print(len(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ECoGTransformerEncoder:\n\tMissing key(s) in state_dict: \"pos_encoder.pos_embedding.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# test model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ECoGTransformerEncoder:\n\tMissing key(s) in state_dict: \"pos_encoder.pos_embedding.weight\". "
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model.load_state_dict(torch.load('transformer_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    loss = criterion(y_pred, y_test)\n",
    "    print(f'Test Loss: {loss.item()}')\n",
    "    y_test = y_test.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    # Plot the first 100 predictions\n",
    "    plt.plot(y_test[:100, 0], label='True X')\n",
    "    plt.plot(y_pred[:100, 0], label='Predicted X')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(y_test[:100, 1], label='True Y')\n",
    "    plt.plot(y_pred[:100, 1], label='Predicted Y')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna, the hyperparameter optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:39:55,156] A new study created in memory with name: no-name-ba7af481-c749-49f2-82cb-30371f7786d9\n",
      "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_32612\\2949406695.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_32612\\2949406695.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-4)\n",
      "[W 2024-07-24 23:39:55,158] Trial 0 failed with parameters: {'model_dim': 512, 'num_heads': 8, 'num_layers': 31, 'dropout_rate': 0.44900400349482184, 'learning_rate': 0.00020727580704592698, 'weight_decay': 1.2991520968685263e-05} because of the following error: TypeError(\"ECoGTransformerEncoder.__init__() missing 1 required positional argument: 'resolution'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_32612\\2949406695.py\", line 25, in objective\n",
      "    model = ECoGTransformerEncoder(input_dim=X_train.shape[-1], model_dim=model_dim, num_heads=num_heads, num_layers=num_layers, output_dim=2, dropout_rate=dropout_rate)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ECoGTransformerEncoder.__init__() missing 1 required positional argument: 'resolution'\n",
      "[W 2024-07-24 23:39:55,161] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ECoGTransformerEncoder.__init__() missing 1 required positional argument: 'resolution'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_optuna:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Best hyperparameters\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[29], line 25\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     22\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, generator\u001b[38;5;241m=\u001b[39mgenerator)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Model and optimizer\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mECoGTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(init_weights)\n\u001b[0;32m     27\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "\u001b[1;31mTypeError\u001b[0m: ECoGTransformerEncoder.__init__() missing 1 required positional argument: 'resolution'"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    model_dim = trial.suggest_categorical('model_dim', [256, 512, 1024])\n",
    "    num_heads = trial.suggest_categorical('num_heads', [8, 16, 32])\n",
    "    num_layers = trial.suggest_int('num_layers',12,32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-4)\n",
    "    \n",
    "    # real data\n",
    "    input_tensor = X_train\n",
    "    target_tensor = y_train\n",
    "    dataset = TensorDataset(input_tensor, target_tensor)\n",
    "    generator = torch.Generator(device='cuda')\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, generator=generator)\n",
    "    \n",
    "    # Model and optimizer\n",
    "    model = ECoGTransformerEncoder(input_dim=X_train.shape[-1], resolution, model_dim=model_dim, num_heads=num_heads, num_layers=num_layers, output_dim=2, dropout_rate=dropout_rate)\n",
    "    model.apply(init_weights)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    # Training loop with mixed precision and gradient checkpointing\n",
    "    scaler = GradScaler()\n",
    "    scheduler = StepLR(optimizer, step_size=num_epochs//7, gamma=0.9)\n",
    "\n",
    "    # Training loop\n",
    "    print(trial.params)\n",
    "    losses = []\n",
    "    for epoch in range(100):\n",
    "        for data, target in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                losses.append(loss.item())\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "    # we want loss direction to be negative\n",
    "    loss_grad = np.mean(losses[2:len(losses)//2]) // np.mean(losses[len(losses)//2:])\n",
    "    return loss_grad\n",
    "\n",
    "if run_optuna:\n",
    "    # Run the optimization\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best trial with output dim 1:\n",
    "\n",
    "[I 2024-07-22 11:58:14,634] Trial 15 finished with value: 753723.5625 and parameters: {'model_dim': 256, 'num_heads': 4, 'num_layers': 5, 'dropout_rate': 0.2259481444219587, 'learning_rate': 0.0009022268315380955}. Best is trial 15 with value: 753723.5625.\n",
    "\n",
    "wrong output dim, trying 2.\n",
    "\n",
    "best: {'model_dim': 512, 'num_heads': 8, 'num_layers': 6, 'dropout_rate': 0.48411131648232686, 'learning_rate': 0.0008203239127338236}\n",
    "\n",
    "new optimization.\n",
    "\n",
    "best: [I 2024-07-23 02:32:30,156] Trial 48 finished with value: 372409.4375 and parameters: {'model_dim': 128, 'num_heads': 8, 'num_layers': 4, 'dropout_rate': 0.3670812456459453, 'learning_rate': 0.0006976310761919828}. Best is trial 48 with value: 372409.4375.\n",
    "\n",
    "new optimization + data formulation: \n",
    "\n",
    "[I 2024-07-23 14:57:13,025] Trial 41 finished with value: 0.005869156192056834 and parameters: {'model_dim': 256, 'num_heads': 8, 'num_layers': 4, 'dropout_rate': 0.44199032873525623, 'learning_rate': 0.0006397189274255495, 'weight_decay': 4.145862002136959e-06}. Best is trial 41 with value: 0.005869156192056834.\n",
    "\n",
    "\n",
    "half run, best: \"{'model_dim': 512, 'num_heads': 8, 'num_layers': 9, 'dropout_rate': 0.14463139530411082, 'learning_rate': 0.0003710353587134264, 'weight_decay': 1.0055811166601365e-06}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
