{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will be trying the transformer architecture\n",
    "This choice is motivated by the fact that the transformer excels at seqtoseq, and is able to capture dependencies spatially and temporally. I hypothesize that this is a good fit for the task since ECOG data is very complex and has dependencies in both time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vectors(coords, resolution):\n",
    "    \"\"\"\n",
    "    Calculate the average vectors of x and y magnitudes given a resolution.\n",
    "\n",
    "    Parameters:\n",
    "    coords (list of tuples): An array of (x, y) coordinates.\n",
    "    resolution (int): The resolution number.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: An array of vectors of x and y magnitudes.\n",
    "    \"\"\"\n",
    "    if resolution <= 0:\n",
    "        raise ValueError(\"Resolution must be a positive integer.\")\n",
    "    \n",
    "    n = len(coords)\n",
    "    if resolution > n:\n",
    "        raise ValueError(\"Resolution cannot be greater than the length of the coordinates array.\")\n",
    "    \n",
    "    # Calculate the segment length\n",
    "    segment_length = n // resolution\n",
    "    \n",
    "    vectors = []\n",
    "    \n",
    "    for i in range(0, n, segment_length):\n",
    "        segment = coords[i:i + segment_length]\n",
    "        if len(segment) < segment_length:\n",
    "            break\n",
    "        \n",
    "        # Calculate the average change in x and y\n",
    "        delta_x = np.mean([segment[j+1][0] - segment[j][0] for j in range(len(segment) - 1)])\n",
    "        delta_y = np.mean([segment[j+1][1] - segment[j][1] for j in range(len(segment) - 1)])\n",
    "        \n",
    "        vectors.append((delta_x, delta_y))\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 5000\n",
    "def vectorize_joystick_readings(x, y, resolution):\n",
    "     return calculate_vectors(list(zip(x, y)), resolution)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica(X, n_components):\n",
    "    ica = FastICA(n_components=n_components)\n",
    "    S_ = ica.fit_transform(X)  # Reconstruct signals\n",
    "    A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "    return S_, A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jstick_data():\n",
    "    # Load and preprocess data\n",
    "    fname = './data/joystick_track.npz'\n",
    "    alldat = np.load(fname, allow_pickle=True)['dat']\n",
    "    dat = alldat[0]\n",
    "    patient_idx = 1\n",
    "    d = dat[patient_idx]\n",
    "    # ecog\n",
    "    ecog_data = d['V'] # Add batch and sequence length dimensions\n",
    "    ecog_data = PCA(n_components=0.95).fit_transform(ecog_data)\n",
    "    # magnitudes\n",
    "    targetX = d['cursorX']\n",
    "    targetY = d['cursorY']\n",
    "    print(ecog_data.shape, targetX.shape, targetY.shape)\n",
    "    resolution = 500\n",
    "    vectors = np.array(vectorize_joystick_readings(targetX, targetY, resolution))\n",
    "    print(vectors.shape)\n",
    "    # match ecog to resolution by grouping, ensuring last sample is not empty\n",
    "    ecog_data = [ecog_data[i:i+len(vectors)] for i in range(0, len(ecog_data), len(ecog_data)//len(vectors)) if i+len(vectors) <= len(ecog_data)]\n",
    "    print(len(ecog_data[0]),len(ecog_data[-1]))\n",
    "    ecog_data = np.array(ecog_data) \n",
    "    return ecog_data, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248640, 28) (248640, 1) (248640, 1)\n",
      "(500, 2)\n",
      "500 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20c79f1bb10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ecog_data, magnitudes = load_jstick_data()\n",
    "plt.figure()\n",
    "plt.scatter([x[0] for x in magnitudes], [x[1] for x in magnitudes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 500, 28) (100, 500, 28) 400 100\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing\n",
    "# train test\n",
    "train_test_split = 0.8\n",
    "train_size = int(train_test_split * len(ecog_data))\n",
    "X_train = ecog_data[:train_size]\n",
    "X_test = ecog_data[train_size:]\n",
    "y_train = magnitudes[:train_size]\n",
    "y_test = magnitudes[train_size:]\n",
    "print(X_train.shape, X_test.shape, len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfromers: robots in disguise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.set_default_device('cuda') if torch.cuda.is_available() else torch.set_default_device('cpu')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :]\n",
    "\n",
    "class ECoGTransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim, dropout_rate=0.1):\n",
    "        super(ECoGTransformerEncoder, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(model_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = checkpoint(self.transformer_encoder, x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Example hyperparameters\n",
    "input_dim = X_train.shape[-1]\n",
    "model_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "output_dim = 2 \n",
    "dropout_rate = 0.48411131648232686\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# quantize the model\n",
    "model = ECoGTransformerEncoder(input_dim, model_dim, num_heads, num_layers, output_dim)\n",
    "\n",
    "# Training loop with mixed precision and gradient checkpointing\n",
    "scaler = GradScaler()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 1000\n",
    "scheduler = StepLR(optimizer, step_size=num_epochs//3, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'model_dim': 512, 'num_heads': 8, 'num_layers': 6, 'dropout_rate': 0.48411131648232686, 'learning_rate': 0.0008203239127338236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "\n",
    "input_tensor = X_train\n",
    "target_tensor = y_train\n",
    "dataset = TensorDataset(input_tensor, target_tensor)\n",
    "generator = torch.Generator(device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 500, 28]) torch.Size([400, 2])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "train = False\n",
    "if train:\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, target in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna, the hyperparameter optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-22 23:10:27,100] A new study created in memory with name: no-name-830fae97-22ad-4d3d-a327-601209c26ffb\n",
      "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_6912\\1910652630.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "[I 2024-07-22 23:12:56,954] Trial 0 finished with value: 856025.9375 and parameters: {'model_dim': 512, 'num_heads': 16, 'num_layers': 5, 'dropout_rate': 0.35444732661750455, 'learning_rate': 5.488641471984078e-05}. Best is trial 0 with value: 856025.9375.\n",
      "[W 2024-07-22 23:14:59,689] Trial 1 failed with parameters: {'model_dim': 512, 'num_heads': 16, 'num_layers': 7, 'dropout_rate': 0.13244720174190228, 'learning_rate': 4.986484728129536e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_6912\\1910652630.py\", line 39, in objective\n",
      "    scaler.step(optimizer)\n",
      "  File \"c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py\", line 453, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py\", line 350, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py\", line 350, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "               ^^^^^^^^\n",
      "  File \"c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\_device.py\", line 78, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-22 23:14:59,691] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_optuna:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Best hyperparameters\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[26], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     37\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     41\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:350\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:350\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    344\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    348\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    349\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    351\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run optuna?\n",
    "run_optuna = True\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    model_dim = trial.suggest_categorical('model_dim', [128, 256, 512])\n",
    "    num_heads = trial.suggest_categorical('num_heads', [4, 8, 16])\n",
    "    num_layers = trial.suggest_int('num_layers', 4,8)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    \n",
    "    # real data\n",
    "    input_tensor = X_train\n",
    "    target_tensor = y_train\n",
    "    dataset = TensorDataset(input_tensor, target_tensor)\n",
    "    generator = torch.Generator(device=device)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, generator=generator)\n",
    "    \n",
    "    # Model and optimizer\n",
    "    model = ECoGTransformerEncoder(input_dim=X_train.shape[-1], model_dim=model_dim, num_heads=num_heads, num_layers=num_layers, output_dim=2, dropout_rate=dropout_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    # Training loop\n",
    "    for epoch in range(100):\n",
    "        for data, target in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "        #print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "if run_optuna:\n",
    "    # Run the optimization\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best trial with output dim 1: [I 2024-07-22 11:58:14,634] Trial 15 finished with value: 753723.5625 and parameters: {'model_dim': 256, 'num_heads': 4, 'num_layers': 5, 'dropout_rate': 0.2259481444219587, 'learning_rate': 0.0009022268315380955}. Best is trial 15 with value: 753723.5625.\n",
    "\n",
    "wrong output dim, trying 2.\n",
    "best: {'model_dim': 512, 'num_heads': 8, 'num_layers': 6, 'dropout_rate': 0.48411131648232686, 'learning_rate': 0.0008203239127338236}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
