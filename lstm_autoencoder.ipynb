{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "fname = './data/joystick_track.npz'\n",
    "alldat = np.load(fname, allow_pickle=True)['dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\thewa\\miniconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (57.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\thewa\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\numpy-1.26.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\numpy-1.26.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\numpy-1.26.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\numpy-1.26.3.dist-info due to invalid metadata entry 'name'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda? True\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:30:10_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\__init__.py:690: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e4c271a890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Is cuda?', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    !nvcc --version\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM Autoencoder Model\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        # Repeat the hidden state for each time step in the sequence\n",
    "        repeated_hidden = hidden.repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
    "        # Decode\n",
    "        decoded, _ = self.decoder(repeated_hidden)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 LSTM models, one for encoding and one for decoding\n",
    "- The encoder LSTM model is used to encode the input sequence into a fixed-length context vector\n",
    "- The decoder LSTM model is used to generate the output sequence from the context vector\n",
    "- In the forward pass, the encoder outputs the hidden and cell states of the LSTM model at the last time step\n",
    "- The context vector is the concatenation of the hidden and cell states of the encoder\n",
    "- the hidden is then repeated for each time step of the decoder\n",
    "- The decoder outputs the hidden and cell states of the LSTM model at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the Data\n",
    "sequence = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "sequence = sequence.reshape((1, len(sequence), 1))  # [samples, timesteps, features]\n",
    "sequence = torch.tensor(sequence, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why is the sequence reshaped before being passed to the tensor?  \n",
    "The input sequence is reshaped to have the batch size as the first dimension and the sequence length as the second dimension, as this is what the LSTM model expects as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "input_dim = 1\n",
    "hidden_dim = 100\n",
    "num_layers = 1\n",
    "num_epochs = 300\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Model, Loss Function, and Optimizer\n",
    "model = LSTMAutoencoder(input_dim, hidden_dim, num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.0532\n",
      "Epoch [100/300], Loss: 0.0178\n",
      "Epoch [150/300], Loss: 0.0022\n",
      "Epoch [200/300], Loss: 0.0018\n",
      "Epoch [250/300], Loss: 0.0010\n",
      "Epoch [300/300], Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    output = model(sequence)\n",
    "    loss = criterion(output, sequence)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence: [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "Reconstructed Sequence: [0.08706661 0.18373486 0.28859183 0.3985688  0.5088333  0.61338407\n",
      " 0.70641994 0.7839322  0.84461796]\n",
      "Accuracy: 99.95346956129652 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the Model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(sequence)\n",
    "    print(\"Original Sequence:\", sequence.detach().cpu().numpy().flatten())\n",
    "    print(\"Reconstructed Sequence:\", reconstructed.detach().cpu().numpy().flatten())\n",
    "    print(\"Accuracy:\", (1 - criterion(reconstructed, sequence).item()) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new hyperparameter\n",
    "future_steps = 3\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Composite LSTM Autoencoder Model\n",
    "class CompositeLSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(CompositeLSTMAutoencoder, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder_reconstruction = nn.LSTM(hidden_dim, input_dim, num_layers, batch_first=True)\n",
    "        self.decoder_prediction = nn.LSTM(hidden_dim, output_dim, num_layers, batch_first=True)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x, future_steps):\n",
    "        # Encode\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        \n",
    "        # Repeat the hidden state for each time step in the sequence\n",
    "        repeated_hidden = hidden.repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
    "        \n",
    "        # Decode for reconstruction\n",
    "        reconstructed, _ = self.decoder_reconstruction(repeated_hidden)\n",
    "        \n",
    "        # Repeat the hidden state for future steps\n",
    "        future_hidden = hidden.repeat(future_steps, 1, 1).permute(1, 0, 2)\n",
    "        \n",
    "        # Decode for prediction\n",
    "        predicted, _ = self.decoder_prediction(future_hidden)\n",
    "        \n",
    "        return reconstructed, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does prediction as well as reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model, Loss Function, and Optimizer\n",
    "model = CompositeLSTMAutoencoder(input_dim, hidden_dim, num_layers, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the Model\n",
    "def train_composite_model(model, sequence, future_steps, num_epochs, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        reconstructed, predicted = model(sequence, future_steps)\n",
    "        loss_reconstruction = criterion(reconstructed, sequence)\n",
    "        loss_prediction = criterion(predicted, sequence[:, :future_steps, :])\n",
    "        loss = loss_reconstruction + loss_prediction\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.0232\n",
      "Epoch [100/300], Loss: 0.0011\n",
      "Epoch [150/300], Loss: 0.0008\n",
      "Epoch [200/300], Loss: 0.0008\n",
      "Epoch [250/300], Loss: 0.0007\n",
      "Epoch [300/300], Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "train_composite_model(model, sequence, future_steps, num_epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence: [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "Reconstructed Sequence: [0.10002718 0.20514363 0.31315318 0.42100808 0.52500767 0.6212813\n",
      " 0.7064799  0.77844024 0.83653086]\n",
      "Predicted Future Sequence: [0.09987517 0.19999722 0.29931393]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the Model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed, predicted = model(sequence, future_steps)\n",
    "    print(\"Original Sequence:\", sequence.detach().cpu().numpy().flatten())\n",
    "    print(\"Reconstructed Sequence:\", reconstructed.detach().cpu().numpy().flatten())\n",
    "    print(\"Predicted Future Sequence:\", predicted.detach().cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for Joystick ECOG Data\n",
    "\n",
    "the plan is to use the auto encoder to train a decoder across all subjects to produce predictions for the joystick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS: LOADING/PROCESSING DATA\n",
    "import math\n",
    "\n",
    "def Vnormalise(_V):\n",
    "    Vmax =  max((max(x) for x in _V))\n",
    "    Vmin = min((min(x) for x in _V))\n",
    "    _V_norm = (_V - Vmin)/(Vmax - Vmin)\n",
    "    return _V_norm\n",
    "\n",
    "def normalise(_V):\n",
    "    _V_norm = (_V - min(_V))/(max(_V) - min(_V))\n",
    "    return _V_norm\n",
    "\n",
    "def Xnormalise(_x, xmin, xmax):\n",
    "    _x_norm = (_x - xmin)/(xmax - xmin)\n",
    "    return _x_norm\n",
    "    \n",
    "def Xdenormalise(_x, xmin, xmax):\n",
    "    _x_denorm = _x*(xmax - xmin) + xmin\n",
    "    return _x_denorm\n",
    "\n",
    "def Ynormalise(_y, ymin, ymax):\n",
    "    _y_norm = (_y - ymin)/(ymax - ymin)\n",
    "    return _y_norm\n",
    "    \n",
    "def Ydenormalise(_y, ymin, ymax):\n",
    "    _y_denorm = _y*(ymax - ymin) + ymin\n",
    "    return _y_denorm\n",
    "\n",
    "  \n",
    "def downsample(signal, factor):\n",
    "  nbins = math.floor(nt/factor)\n",
    "  signal_norm = np.zeros((nbins, 1))\n",
    "  for ibin in range(nbins):\n",
    "    binstart = ibin * factor\n",
    "    binend = binstart + factor\n",
    "    signal_norm[ibin, 0] = np.mean(signal[binstart:binend])\n",
    "\n",
    "  return signal_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = alldat[0]\n",
    "\n",
    "# i need to pass the data for each subject to the encoder, which then \n",
    "for d in dat:\n",
    "    _V = d['V']\n",
    "    _V_norm = Vnormalise(_V)\n",
    "    _V_norm = _V_norm.reshape(-1, 1)\n",
    "    nt = _V_norm.shape[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait, this model is wrong\n",
    "\n",
    "I need a model that can take all the ecog data, produce low dimensional representation, and then use that to predict the X, Y magnitude vectors of the target on the screen as produced by some transformation of the cursorX and cursorY values. This \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda? True\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:30:10_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('Is cuda?', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    !nvcc --version\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372760, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_joystick_readings(x, y):\n",
    "    # adjust the range of the readings to be between 0 and 1\n",
    "    x_magnitude = normalise(x)\n",
    "    y_magnitude = normalise(y)\n",
    "    return x_magnitude, y_magnitude\n",
    "\n",
    "\n",
    "# choose patient\n",
    "patient_idx = 0\n",
    "\n",
    "d = dat[patient_idx]\n",
    "targetX = d['targetX']\n",
    "targetY = d['targetY']\n",
    "# Normalize the readings\n",
    "x_magnitude, y_magnitude = normalize_joystick_readings(targetX, targetY)\n",
    "\n",
    "magnitudes = np.concatenate((x_magnitude, y_magnitude), axis=1)\n",
    "print(magnitudes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372760, 60)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class JoystickDataset(Dataset):\n",
    "    def __init__(self, ecog_data, magnitudes):\n",
    "        self.ecog_data = ecog_data\n",
    "        self.magnitudes = magnitudes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ecog_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.ecog_data[idx]\n",
    "        y = self.magnitudes[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Example: Load your ECOG data here\n",
    "ecog_data =  d['V']\n",
    "\n",
    "# Create dataset and dataloader\n",
    "# ecog is x, magnitudes is y\n",
    "dataset = JoystickDataset(ecog_data, magnitudes)\n",
    "generator = torch.Generator(device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, generator=generator)\n",
    "print(ecog_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.functional import F\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.lstm = nn.LSTM(64 * 15 * 15, 128, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension: [batch_size, 1, channels, time_points]\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1, 64 * x.size(2) * x.size(3))  # Reshape for LSTM: [batch_size, sequence_length, features]\n",
    "        x, _ = self.lstm(x)\n",
    "        return x[:, -1, :]  # Take the output of the last time step\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CoordPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)  # Output x and y coordinates\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.coord_predictor = CoordPredictor()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        coords = self.coord_predictor(features)\n",
    "        return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (32x1x60). Calculated output size: (32x0x30). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (ecog_data, target_coords) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecog_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, target_coords)\n\u001b[0;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m, in \u001b[0;36mCombinedModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 8\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_predictor(features)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m coords\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m, in \u001b[0;36mFeatureExtractor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add channel dimension: [batch_size, 1, channels, time_points]\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# Reshape for LSTM: [batch_size, sequence_length, features]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:164\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\_jit_internal.py:499\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (32x1x60). Calculated output size: (32x0x30). Output size is too small"
     ]
    }
   ],
   "source": [
    "# Assuming you have your data loaders ready\n",
    "model = CombinedModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (ecog_data, target_coords) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ecog_data)\n",
    "        loss = criterion(outputs, target_coords)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[24000, 1]' is invalid for input of size 400",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 5\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(hidden\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[144], line 10\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 10\u001b[0m     _, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[24000, 1]' is invalid for input of size 400"
     ]
    }
   ],
   "source": [
    "# pass dataset through encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thewa\\AppData\\Local\\Temp\\ipykernel_15492\\1184376144.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "Epoch [10/50], Loss: 150.2608\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "Epoch [20/50], Loss: 1.3982\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "Epoch [30/50], Loss: 0.7412\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n",
      "torch.Size([1, 60, 372760])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Training Loop with dataloader\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 75\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mecog_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_coords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:621\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter)\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:287\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    286\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 287\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_in_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\thewa\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:168\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels, sequence_length):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        # Calculate the output size after convolution and pooling\n",
    "        conv_output_length = sequence_length // 4  # Two pooling layers with kernel size 2\n",
    "        self.fc1 = nn.Linear(64 * conv_output_length, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class PredictionModel(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(PredictionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(feature_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class ECoGModel(nn.Module):\n",
    "    def __init__(self, input_channels, sequence_length):\n",
    "        super(ECoGModel, self).__init__()\n",
    "        self.feature_extractor = FeatureExtractor(input_channels, sequence_length)\n",
    "        self.prediction_model = PredictionModel(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        predictions = self.prediction_model(features)\n",
    "        return predictions\n",
    "\n",
    "# Hyperparameters\n",
    "input_channels = 60\n",
    "sequence_length = 372760  # Adjust based on your data\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "model = ECoGModel(input_channels, sequence_length)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Dummy Data for illustration purposes\n",
    "# Replace with actual ECoG data and target coordinates\n",
    "ecog_data = torch.randn(1, input_channels, sequence_length)  # (batch_size, channels, sequence_length)\n",
    "target_coords = torch.randn(sequence_length, 2)  # (sequence_length, 2)\n",
    "# real data: (sequence_length, in_channels) as ( (372760, 60) for ecog, coordinate magnitudes as (372760, 2)\n",
    "# add batch dimension to ecog_data numpy array\n",
    "dataset = JoystickDataset(ecog_data, target_coords)\n",
    "generator = torch.Generator(device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, generator=generator)\n",
    "# Training Loop with dataloader\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (ecog_data, target_coords) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        print(ecog_data.shape)\n",
    "        outputs = model(ecog_data)\n",
    "        loss = criterion(outputs, target_coords)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[218], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(target_coords[:, \u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget X Coordinate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(target_coords[:, \u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget Y Coordinate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted X Coordinate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()[:, \u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Y Coordinate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check if data is in cuda tensor\n",
    "if torch.cuda.is_available():\n",
    "    ecog_data = ecog_data.cpu()\n",
    "    target_coords = target_coords.cpu()\n",
    "    outputs = outputs.cpu()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(target_coords[:, 0], label='Target X Coordinate')\n",
    "plt.plot(target_coords[:, 1], label='Target Y Coordinate')\n",
    "plt.plot(outputs.squeeze(0).detach()[:, 0], label='Predicted X Coordinate')\n",
    "plt.plot(outputs.squeeze(0).detach()[:, 1], label='Predicted Y Coordinate')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Coordinate Value')\n",
    "plt.title('ECoG Data Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nma-compneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
